"""-*-python-*-
suggested use:
place a dotted symlink to this
file in your home directory
  ln -s /.../pythonrc ~/.pythonrc
and set the environment variable
PYTHONSTARTUP
to the symlink
export PYTHONSTARTUP="${HOME}/.pythonrc"
see also:
https://docs.python.org/3/using/cmdline.html#envvar-PYTHONSTARTUP
"""

from typing import (
    Dict,
)
from collections import (
    namedtuple,
)
import datetime as dt
from datetime import (
    datetime as dto,
    timedelta,
)
from functools import (
    reduce,
    partial,
    wraps,
)
from inspect import (
    getmembers as gm,
    getsource,
    getsourcefile as gsf,
    getmodule,
    ismodule,
    isclass,
)
import operator as op
from operator import (
    add,
    itemgetter as ig,
    attrgetter,
)
import os
import sys
import os.path as pth
import random
from pprint import (
    pp,
    pprint,
)
import math
from copy import (
    deepcopy,
)

import pydoc
from pydoc import (
    pager,
)

import curses
import curses.textpad


import subprocess
from subprocess import (
    Popen,
    PIPE,
)

import shlex

import configparser

import pathlib

from io import (
    BytesIO,
    StringIO,
)

from warnings import warn

import zipfile

import gzip
from gzip import (
    GzipFile,
)

from tempfile import (
    gettempdir,
    mkdtemp,
)

import json

from importlib import (
    reload,
)

import shutil
from shutil import (
    copyfileobj,
)

import threading
import asyncio
import queue

import signal

import time

import tkinter

import rlcompleter
import readline
readline.parse_and_bind("tab: complete")

###


def ppp(obj):
    sio = StringIO()
    pprint(obj, stream=sio)
    pager(sio.getvalue())


def gmn(*args, **kwargs):
    return [m[0] for m in gm(*args, **kwargs)]


def gs(*args, **kwargs):
    pydoc.pager(getsource(*args, **kwargs))


inc = lambda x: x + 1
dec = lambda x: x - 1


class Leaf:
    pass


class Branch:
    pass


class Tree:
    pass


class NameSpace:
    def __init__(self, obj):
        self._obj = obj

    def names(self):
        if ismodule(self._obj):
            return dir(self._obj)
        elif isclass(self._obj):
            return dir(self._obj)
        assert False, repr(self._obj) + " is not a module or class"

    def attrs(self):
        return map(partial(getattr, self._obj), self.names())

    def namespaces(self):
        [Namespace(attr) for attr in self.attrs() if any(juxt(ismodule, isclass)(attr))]


def pysearch_name(name, maxdepth=3):
    res = []
    permissive_getattr = excepts(
        (ModuleNotFoundError, AttributeError), partial(getattr), lambda _: None
    )

    def name_match(mname):
        return name in mname

    res += [sys.modules[mname] for mname in sys.modules.keys() if name_match(mname)]

    def search_class(cls):
        for mname in dir(cls):
            if name_match(mname):
                res.append(permissive_getattr(cls, mname))

    def search_module(module, depth):
        if depth > maxdepth:
            return
        if name in dir(module):
            res.append(permissive_getattr(module, name))
        for (mname, member) in [
            (mname, permissive_getattr(module, mname)) for mname in dir(module)
        ]:
            if not member:
                continue
            if name_match(mname):
                res.append(member)
            if isinstance(member, type):
                search_class(member)
            if ismodule(member):
                search_module(member, depth + 1)

    for mname in list(sys.modules.keys()):
        search_module(sys.modules[mname], 0)
    return res


ls = os.listdir


def cat(filepath, retstr=False):
    with open(filepath) as f:
        fstr = f.read()
    if retstr:
        return fstr
    pydoc.pager(fstr)


run = partial(
    subprocess.run,
    stdout=subprocess.PIPE,
    stderr=subprocess.PIPE,
    # shell=True,
    # check=True,
)


def run_1(cmd, timeout=None, stream=sys.stdout, err_stream=sys.stderr):
    def output_reader(proc):
        for line in iter((proc.stdout.readline if proc.stdout else lambda: b""), b""):
            print(line.decode("utf-8"), file=stream, end="")
        return

    def err_reader(proc):
        for line in iter((proc.stderr.readline if proc.stderr else lambda: b""), b""):
            print(line.decode("utf-8"), file=err_stream, end="")
        return
        # todo: copyfileobj with .decode("utf-8") wrapper
        proc_strm = proc.stderr or b""

    proc = Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)
    tout = threading.Thread(target=output_reader, args=(proc,))
    terr = threading.Thread(target=err_reader, args=(proc,))
    tout.start()
    terr.start()
    proc.wait(timeout=timeout)
    tout.join()
    terr.join()


config = configparser.ConfigParser()
config.read(
    [
        os.path.join(os.path.dirname(os.path.realpath(__file__)), "python.conf"),
    ]
)


class PipInstallException(Exception):
    pass


# todo: --cache-dir option,
#    possibly following pre-commit cache strategy
# todo(???): build wheels
def pip_install(package_name):
    name_to_specifier = {
        name: config["package-specifiers"][name]
        for name in config["package-specifiers"]
    }
    if package_name not in name_to_specifier:
        if os.getenv("PY_DBG_IMPORTS"):
            breakpoint()
        raise PipInstallException("unknown package", (package_name,))
    cmd = ["pip", "install", name_to_specifier[package_name]]
    res = subprocess.run(cmd)
    if res.returncode == 0:
        return
    raise PipInstallException("install failed", (res,))


###
_VENV_DIR = pth.join(str(pathlib.Path().home()), ".pyvenv")
_DEFAULT_VENV = pth.join(_VENV_DIR, "default")
if sys.prefix == sys.base_prefix:
    if not os.getenv("PY_CREATE_VENV"):
        raise Exception("not in venv.  set PY_CREATE_VENV to create")
    venv.create(_DEFAULT_VENV)
    print(". " + pth.join(_DEFAULT_VENV, "bin", "activate"))
    exit()


class ImportBlocker(object):
    def __init__(self):
        self.module_names = set()
        self.package_names = set()

    def find_module(self, fullname, path=None):
        if fullname.split(".")[0] in self.package_names:
            return self
        if fullname in self.module_names:
            return self
        return None

    def exec_module(self, mdl):
        # return an empty namespace
        return {}

    def create_module(self, spec):
        return None


import_blocker = ImportBlocker()
sys.meta_path.append(import_blocker)


def my_except_hook(exctype, value, traceback):
    if exctype is KeyboardInterrupt:
        print("see you later!")
    sys.__excepthook__(exctype, value, traceback)


def install_package(name):
    pass


sys.excepthook = my_except_hook

while True:
    try:
        import toolz
        import toolz.functoolz as ftlz
        import toolz.itertoolz as itlz
        import toolz.dicttoolz as dtlz
        from toolz.functoolz import (
            compose_left,
            excepts,
            compose,
            curry,
            flip,
            juxt,
            thread_last,
        )
        from toolz.itertoolz import (
            accumulate,
            concat,
            concatv,
            cons,
            diff,
            first,
            isdistinct,
            groupby,
            mapcat,
            nth,
            unique,
        )
        from toolz.dicttoolz import (
            keymap,
            valmap,
            itemmap,
        )
        from toolz.curried import (
            get,
            keyfilter,
            valfilter,
            itemfilter,
        )

        import numpy as np
        import flask
        import werkzeug
        import ics
        import uuid0
        import lxml
        import pandas as pd
        import openpyxl
        import openpyxl.utils.dataframe
        import wiktionaryparser
        from wiktionaryparser import WiktionaryParser
        import shapely
        import shapely.geometry
        from shapely.geometry import (
            LineString,
        )
        import pyproj
        import matplotlib
        from matplotlib import pyplot
        import requests
        import bs4
        from bs4 import BeautifulSoup as BS
        import npyscreen

        # without Qt install (see python.conf)
        # gui `pymol.lauch([])` is inoperative
        # and this package is at most useful
        # to parse file formats (protien database -- .pdb), etc.
        import pymol

        from aiohttp import (
                web as aioweb,
                )
        import aiohttp_wsgi

        import urwid

        import supermemo2
        import supermemo2.sm_two
        from supermemo2 import SMTwo

        sys.path.append(os.path.dirname(os.path.realpath(__file__)))
        import pyutils

        sys.path.pop()

    except ModuleNotFoundError as err:
        package_name = err.name
        try:
            print("attempting to install " + package_name)
            pip_install(package_name)
        except PipInstallException as ex:
            if os.getenv("PY_DBG_IMPORTS"):
                breakpoint()
            import_blocker.package_names.add(package_name)
        continue
    break


# reset to orig
# sys.excepthook = sys.__excepthook__

uninstalled_packages = import_blocker.package_names.copy()
if uninstalled_packages:
    print("uninstalled packages")
    print(uninstalled_packages)

###


def osm_to_shp(filename):
    with open(filename) as f:
        fstr = f.read()
        root = lxml.etree.XML(bytes(fstr, "utf-8"))
    tags = [t.tag for t in root]
    assert root.tag == "osm"
    assert set(tags) <= {"node", "relation", "way", "bounds"}
    assert root[0].tag == "bounds"
    assert set(tags[1:]) <= {"node", "relation", "way"}
    assert "way" not in tags or (set(tags[tags.index("way") :]) <= {"relation", "way"})
    assert "relation" not in tags or (
        set(tags[tags.index("relation") :]) <= {"relation"}
    )
    nodes = [el for el in root if el.tag == "node"]
    ways = [el for el in root if el.tag == "way"]
    relations = [el for el in root if el.tag == "relation"]
    bounds_dict = dict(root[0].items())
    min_bound = (bounds_dict["minlat"], bounds_dict["minlon"])
    max_bound = (bounds_dict["maxlat"], bounds_dict["maxlon"])

    # (beginnings of) some cleverness
    juxt(map(compose(keyfilter, flip(str.startswith)), ["min", "max"]))(bounds_dict)

    ### munging #

    el_attrs = lambda x: dict(x.items())
    attr_eq = lambda name, val: (compose(partial(op.eq, val), attrgetter(name)))
    has_tag = lambda el, tag_name: any(
        [
            True
            for x in el
            if (x.tag == "tag" and "k" in el_attrs(x) and el_attrs(x)["k"] == tag_name)
            # (attr_eq('tag', 'tag')(x) and "k" in el_attrs(x) and get("k")(el_attrs(x)) == tag_name)
            # (attr_eq('tag', 'tag')(x) and compose(flip(op.contains, 'k'), el_attrs)(x) and compose(partial(op.eq, tag_name), get("k"), el_attrs)(x))
            # compose(all, juxt(attr_eq('tag', 'tag')(x), compose(partial(op.eq, tag_name), get("k", default=None), el_attrs)))(x)
        ]
    )
    # errors if tag nexist...
    # ... idea: duplicate get() semantics
    get_tag = lambda el, tag_name: ftlz.pipe(
        list(el),
        partial(
            filter,
            compose(
                all,
                juxt(
                    attr_eq("tag", "tag"),
                    compose_left(
                        el_attrs,
                        get("k", default=None),
                        partial(op.eq, tag_name),
                    ),
                ),
            ),
        ),
        first,
        compose_left(el_attrs, get("v")),
    )

    #    filter(compose_left(el_attrs, get('k'), partial(op.eq, 'highway')),
    #    filter(compose_left(el_attrs, flip(op.contains, 'k')),
    #        filter(compose(partial(op.eq, 'tag'), attrgetter('tag')),
    #            list(ways[2]))))

    waterways = list(filter(flip(has_tag, "waterway"), ways))
    highways = list(filter(flip(has_tag, "highway"), ways))
    named_highways = list(filter(flip(has_tag, "name"), highways))

    assert len(set(map(compose(ig("id"), el_attrs), nodes))) == len(
        nodes
    ), "nodes have unique ids"
    nodes_by_id = {el_attrs(n)["id"]: n for n in nodes}

    way_to_lat_lons = compose_left(
        list,
        partial(filter, attr_eq("tag", "nd")),
        partial(
            map,
            compose_left(
                el_attrs,
                ig("ref"),
                flip(get, nodes_by_id),
                el_attrs,
                get(["lat", "lon"]),
                compose(
                    list,
                    partial(map, float),
                ),
            ),
        ),
        list,
    )

    return {
        "named_highways": dict(
            zip(
                list(map(flip(get_tag, "name"), named_highways)),
                map(LineString, list(map(way_to_lat_lons, named_highways))),
            )
        ),
        "bounds": {
            "dict": bounds_dict,
            "box": shapely.geometry.box(
                bounds_dict["minlat"],
                bounds_dict["minlon"],
                bounds_dict["maxlat"],
                bounds_dict["maxlon"],
            ),
        },
    }

    # introspection on data format
    ways_keys = thread_last(
        ways,
        (mapcat, list),
        (filter, attr_eq("tag", "tag")),
        (map, el_attrs),
        (map, ig("k")),
        set,
    )


def plot_osm_shp(shpd):
    breakpoint()
    pass


lastfn = lambda: plot_osm_shp(osm_to_shp("Downloads/map.osm"))


def view_pdb(db_id: str):
    fn = view_pdb
    garlic_exec = fn.garlic_exec
    cache_dir = fn.cache_dir_path
    if not pth.exists(cache_dir):
        os.mkdir(cache_dir)
    download_url_base = fn.download_url_base
    pdb_file_path = pth.join(
        cache_dir,
        "{db_id}.pdb".format(
            db_id=db_id,
        ),
    )
    pdb_archive_path = pth.join(
        cache_dir,
        "{db_id}.pdb.gz".format(
            db_id=db_id,
        ),
    )

    #    breakpoint()

    pdb_file_url = requests.compat.urljoin(
        download_url_base,
        "{db_id}.pdb".format(
            db_id=db_id,
        ),
    )
    pdb_archive_url = requests.compat.urljoin(
        download_url_base,
        "{db_id}.pdb.gz".format(
            db_id=db_id,
        ),
    )

    if not pth.exists(pdb_file_path) and not pth.exists(pdb_archive_path):
        res: request.models.Response = requests.get(pdb_archive_url, stream=True)
        assert res.status_code == 200
        chunks = res.iter_content(
            # read data in "whatever size the chunks are recv'd"
            # todo: extract personal dsl fn, documenting the "whatever"
            chunk_size=None,
        )
        with open(pdb_archive_path, "wb") as f:
            for chunk in chunks:
                f.write(chunk)

    if not pth.exists(pdb_file_path):
        with gzip.open(pdb_archive_path) as f_gz, open(pdb_file_path, "wb") as f:
            shutil.copyfileobj(f_gz, f)

    #    breakpoint()
    proc = Popen([garlic_exec, pdb_file_path])
    # todo: workaround garlic numeric keypad requirement
    #   - forward keys from python terminal
    #   - wrap window (X11 or other layer) to access keys
    #          while view selected.
    try:
        print("interrupt Ctl-c to exit")
        while True:
            time.sleep(1024)
    except KeyboardInterrupt:
        pass
    finally:
        proc.terminate()
        print("waiting on garlic exit")
        proc.wait()

    return

    # attempts at optimization
    with open() as f:
        with GzipFile(
            f,
            # default 'rb'.  no text mode opt here.  gzip.open() only
            mode="rb",
        ) as gf:
            gf.read1()


view_pdb.download_url_base = "https://files.rcsb.org/download/"
view_pdb.garlic_exec = "garlic"
view_pdb.cache_dir_path = pth.join(gettempdir(), "view_pdb_cache_dir")


# todo: scrape wikipedia page to pdb code
#    https://en.wikipedia.org/wiki/Muscarinic_acetylcholine_receptor_M4
# todo: search wikipedia page (NLP+force(?))
#    to receptors (pages w/ pdb codes)


def xlst_to_dataframes(filepath):
    wb = openpyxl.load_workbook(filepath)
    return {sn: pd.DataFrame(wb[sn].values) for sn in wb.sheetnames}


def dataframes_to_xlst(dfs: Dict[str, pd.DataFrame], filepath):
    wb = openpyxl.Workbook()
    wb.active
    for (nm, df) in dfs.items():
        ws = wb.create_sheet(nm)
        ws.title
        for row in openpyxl.utils.dataframe.dataframe_to_rows(
            df, index=True, header=True
        ):
            ws.append(row)
    wb.save(filepath)

##>>>##

###
# simple time-boxing and -estimation setup
#
# todo:
#* persistent dict (to disk)
#* calc time estimate sums
#

# activity to minutes
_TIME_ESTIMATE = {}


def _espeak_text(
        text,
        vol=9,
        disp=True,
):
    if disp:
        rainbow_print(text)
    subprocess.run(
        ['espeak',
         '-v', 'f4',
         '-p', '135',
         '-a', str(vol)
         ],
        input=bytes(text, 'utf-8'),
    )


def _xmessage_text(
        text,
        disp=True,
):
    if disp:
        rainbow_print(text)
    proc = subprocess.Popen(
        ['xmessage',
         text,
         ],
    )
    return proc



def print_time_estimates():
    pp(_TIME_ESTIMATE)
    # todo: calculate sums


def add_time_estimate_task(
        key_or_ks,
        minutes=None,
):
    if isinstance(key_or_ks, (str,)):
        key = key_or_ks
        act = key #activity
        # if act in _TIME_ESTIMATE:
        #     raise ValueError(
        #         "activity already exists",
        #         (act,))
        minutes = (input(("how long will '"
                          +act+
                          "' take? >[minutes]> ")) if minutes is None else float(minutes))
        _TIME_ESTIMATE[act] = float(minutes)
    elif isinstance(key_or_ks, (list,)):
        ks = key_or_ks
        raise ValueError(
            "nested activities unimplemented",
            (ks,))
    else:
        raise RuntimeError(
            "unknown activity specification",
            (key_or_ks, type(key_or_ks),))


def do_time_estimated_task(
        key_or_ks=None,
        min_warning=2.,
        mute=True,
):
    if key_or_ks == None:
        print("given options")
        print("-------------")
        print_time_estimates()
        print("----")
        for v in _TIME_ESTIMATE.values():
            if not isinstance(v, (int,)):
                raise NotImplementedError(
                    "nested activities unimpl")
        key = ''
        while not key or key not in _TIME_ESTIMATE:
            # todo: tab-completion
            key = input((
                "what task do you want"
                " to work on? )]} "))
            if key not in _TIME_ESTIMATE:
                print(("unknown activity '"+
                       key
                       +"'. "
                       "activities to choose from"
                       " are:"))
                print(', '.join(["'"+act+"'" for act in
                           _TIME_ESTIMATE.keys()]))
        key_or_ks = key
    #
    if isinstance(key_or_ks, (str,)):
        key = key_or_ks
        act = key
        est_min = _TIME_ESTIMATE[key]
        if est_min is None:
            print("no time estimate for '"+act+"'")
        elif not isinstance(est_min, (int, float,)):
            raise ValueError(
                "nested activities unimplemented",
                (est_min,))
        msg_begin = "fine, take "+str(est_min)+" minutes"
        rainbow_print(msg_begin)
        if not mute:
            _espeak_text(msg_begin)
        sec_wait = float(60.*(float(est_min)-float(min_warning)))
        PROG_BAR_STEPS = 10
        step_sec_wait = sec_wait/float(PROG_BAR_STEPS)
        for _ in range(PROG_BAR_STEPS):
            # print("waiting "+str(step_sec_wait), file=sys.stderr,)
            time.sleep(step_sec_wait)
            print('.', end='')
            sys.stdout.flush()
        print()
        msg_warn = ("you have "+str(min_warning)+" minutes left to finish "+
                    act)
        rainbow_print(msg_begin)
        if not mute:
            _espeak_text(msg_warn)
        warn_xm_proc = _xmessage_text(msg_warn)
        sec_wait = 60.*min_warning
        step_sec_wait = sec_wait/float(PROG_BAR_STEPS)
        for _ in range(PROG_BAR_STEPS):
            time.sleep(step_sec_wait)
            print('.', end='')
            sys.stdout.flush()
        print()
        msg_end = ("time's up!  your estimate of "+str(est_min)+" minutes "
                   "to completely complete "+act+" has elapsed. ")
        rainbow_print(msg_begin)
        if not mute:
            _espeak_text(msg_end)
        end_xm_proc = _xmessage_text(msg_end)
        warn_xm_proc.terminate()
        warn_xm_proc.wait()
        finished = None
        while finished is None:
            finished_txt = input("did you finish??? >[yes/no]>> ").strip()
            if finished_txt not in ['yes', 'no',]:
                print("please answer 'yes' or 'no'")
                continue
            finished = finished_txt == 'yes'
        end_xm_proc.terminate()
        end_xm_proc.wait()
        if finished:
            del _TIME_ESTIMATE[key]
            # todo: pos/neg-reinforcement
        else:
            _TIME_ESTIMATE[key] = None
            print("your time-estimate has been discarded.  "
                  # ^ irl stuff.
                  "to add a new estimate:")
            print("add_time_estimate_task('"+key+"')")
    elif isinstance(key_or_ks, (list,)):
        ks = key_or_ks
        raise ValueError(
            "nested activities unimplemented",
            (ks,))
    else:
        raise RuntimeError(
            "unknown activity specification",
            (key_or_ks, type(key_or_ks),))


_FLASHCARD_BASE_PATH = gettempdir()
_FLASHCARD_CSV_DATA_PATH = pth.join(_FLASHCARD_BASE_PATH, "flashcard_data.csv")


def set_flashcard_deck():
    global _FLASHCARD_BASE_PATH
    raise NotImplementedError()





_FLASHCARD_EMPTY_DF = pd.DataFrame({
    'jpn': pd.Series([]),
    'eng': pd.Series([]),
    'phonetic': pd.Series([]),
})

def _create_flashcard_csv(column_names):
    df = pd.DataFrame({
        column_name: pd.Series([], dtype='str') for column_name in column_names
    })
    if pth.exists(_FLASHCARD_CSV_DATA_PATH):
        warn("overwriting " + _FLASHCARD_CSV_DATA_PATH)
    with open(_FLASHCARD_CSV_DATA_PATH, 'w') as f:
        df.to_csv(f, index=False,)


def _read_flashcard_csv():
    with open(_FLASHCARD_CSV_DATA_PATH) as f:
        return pd.read_csv(f)


def _add_to_flashcard_csv(vals: Dict[str, str]):
    df = _read_flashcard_csv()
    assert set(vals.keys()) == set(df.columns), (
        "adding data without extant column names"
        "or"
        "missing columns")
    for col in df.columns:
        if vals[col] in df[[col]]:
            raise ValueError("duplicate value in column",
                             (col, vals[col],))
    df = df.append(
        pd.Series([vals[col] for col in df.columns],
                  dtype=str,
                  index=df.columns),
        ignore_index=True,
    )
    with open(_FLASHCARD_CSV_DATA_PATH, 'w') as f:
        df.to_csv(f, index=False,)


def _update_flashcard_csv(vals: Dict[str, str]):
    df = _read_flashcard_csv()
    assert len(vals) > 1
    assert set(vals.keys()) <= set(df.columns)
    raise NotImplementedError()


def currfn():
    _create_flashcard_csv([
        'jpn',
        'eng',
        'phonetic',
    ])
    _add_to_flashcard_csv({
        'jpn': '風chongfeng',
        'eng': 'wind',
        'phonetic': 'Kaze',
    })
    _add_to_flashcard_csv({
        'jpn': '水shui',
        'eng': 'water',
        'phonetic': 'Mizu',
    })
    flashcard_data = _read_flashcard_csv()
    print("flashcard_data")
    print(flashcard_data)



def add_flashcard_data(
        vals: Dict[str, str],
):
    if not pth.exists(_FLASHCARD_CSV_DATA_PATH):
        with open(_FLASHCARD_CSV_DATA_PATH, 'w') as f:
            _FLASHCARD_EMPTY_DF.to_csv(f)

    with open(_FLASHCARD_CSV_DATA_PATH) as f:
        df = pd.read_csv(f)

    assert set(vals.keys()) == set(df.columns), (
        "adding data without extant column names"
        "or"
        "missing columns")

    if set(vals.keys()) != set(_FLASHCARD_DF.columns):
        warn(("adding data without extant column names"
              "or"
              "missing columns"))
        ValueError()


    df = df.append(
        pd.Series(['X', 'Z',],
                  dtype=str,
                  index=df.columns),
        ignore_index=True,
    )


    _FLASHCARD_DF


    return


    df = pd.DataFrame({
        'A': pd.Series([1, 2,]),
        'B': pd.Series([3, 4,]),
    })
    breakpoint()
    df = df.append(
        pd.Series(['X', 'Z',],
                  index=df.columns),
        ignore_index=True,
    )
    df = df.append(
        pd.Series(['T', 'Y', "P",]),
        ignore_index=True,
    )
    breakpoint()
    df.append(
        pd.Series(['X0', 'Z9',],
                  index=df.columns)
    )
    breakpoint()
    raise NotImplementedError()


def read_flashcard_data():

    raise NotImplementedError()


def edit_flashcard():
    raise NotImplementedError()


def nextfn():
    add_flashcard_data({
        'jpn': '風',
        'eng': 'eng',
        'phonetic': 'Kaze',
    })
    add_flashcard_data({
        'jpn': '水',
        'eng': 'water',
        'phonetic': 'Mizu',
    })
    flashcard_data = read_flashcard_data()

    # 'コウモリ'


def _sim_practice_flashcards():

    _MIN_QUALITY = 0
    _MAX_QUALITY = 5

    cards = [
        {'sides': ('card-'+str(x), x),
         'reviews': [],
         }
        for x in range(_MIN_QUALITY, _MAX_QUALITY)
    ]

    first_review_date = dt.date.today()

    init_reviews = {card['reviews']: SMTwo.first_review(i, first_practice_date)
                    for (i, card,) in enumerate(cards)}


    first_practice_date = dt.date.today()
    second_practice_date = first_practice_date + dt.timedelta(days=1)
    third_practice_date = second_practice_date + dt.timedelta(days=3)

    first_reviews = [SMTwo.first_review(x, first_practice_date) for x in range(6)]
    second_reviews = [
        deepcopy(first_review).review(x, second_practice_date)
        for first_review in first_reviews
        for x in range(6)]

    first_review_dates = set([r.review_date for r in first_reviews])
    second_review_dates = set([r.review_date for r in second_reviews])

    print("review dates")
    print(first_review_dates)
    print(second_review_dates)

    print("review intervals")
    print(set(map(attrgetter('interval'), first_reviews)))
    print(set(map(attrgetter('interval'), second_reviews)))

    breakpoint()




def practice_flashcards():
    # todo: reverse-order difficulty
    def get_difficulty_input():
        difficulty = None
        while difficulty is None:
            difficulty_input = input('how difficult was that? [1-3] >>>')
            try:
                difficulty = int(difficulty_input)
            except ValueError:
                pass
            if difficulty is not None and difficulty < 1 or difficulty > 3:
                print("difficulty between 1, 2, or 3")
                difficulty = None
        return difficulty

    def get_resp_input(card, print_correctness=True):
        resp = input(card[0] + ' >>> ')
        if resp == card[1]:
            print("correct")
            return True
        else:
            print("incorrect")
            return False


    cards = (
        ('one', '1', []),
        ('two', '2', []),
        # ('three', '3', []),
    )

    curr_date = first_practice_date
    for card in cards:
        resp = input(card[0] + ' >>> ')
        if resp == card[1]:
            print("correct")
        else:
            print("incorrect")
        difficulty = get_difficulty_input()
        curr_card_review = SMTwo.first_review(difficulty, curr_date)
        card[2].append(curr_card_review)

    curr_date = second_practice_date
    for card in cards:
        resp = input(card[0] + ' >>> ')
        if resp == card[1]:
            print("correct")
        else:
            print("incorrect")
        difficulty = get_difficulty_input()
        prev_review = card[2][-1]
        curr_card_review = prev_review.review(difficulty, curr_date)
        card[2].append(curr_card_review)



##<<<##


def ensure_lang_name_codes(fn):
    cache_file_path = ensure_lang_name_codes.cache_file_path
    download_url = ensure_lang_name_codes.download_url

    def get_lang_name_codes_data():
        if pth.exists(cache_file_path):
            with open(cache_file_path) as f:
                return f.read()
        res = requests.get(download_url)
        assert res.status_code == 200
        lang_name_codes_data = res.text.replace("\r", "")
        with open(cache_file_path, "w") as f:
            f.write(lang_name_codes_data)
        return lang_name_codes_data

    def get_lang_name_codes():
        data = get_lang_name_codes_data()
        data = list(map(flip(str.split, "\t"), filter(op.truth, data.split("\n"))))
        assert data[0] == ["Id", "Print_Name", "Inverted_Name"]
        rows = data[1:]
        if len(set(map(ig(0), rows))) != len(rows):
            warn("name codes not uniq")
        return {"rows": rows}

    @wraps(fn)
    def wrapped(*args, **kwargs):
        return fn(get_lang_name_codes(), *args, **kwargs)

    return wrapped


# todo: study pre-commit caching strategy
ensure_lang_name_codes.cache_file_path = pth.join(
    gettempdir(), "lang_name_codes__pycache.tsv"
)
# ref. https://iso639-3.sil.org/code_tables/download_tables
ensure_lang_name_codes.download_url = (
    "https://iso639-3.sil.org/sites/iso639-3/files/downloads/iso-639-3_Name_Index.tab"
)


@ensure_lang_name_codes
def ensure_freedict_db_index(lang_name_codes, fn):
    cache_file_path = ensure_freedict_db_index.cache_file_path
    download_url = ensure_freedict_db_index.download_url

    def get_freedict_db_index_data():
        if pth.exists(cache_file_path):
            with open(cache_file_path) as f:
                return f.read()
        res = requests.get(download_url)
        assert res.status_code == 200
        freedict_db_index_data = res.text.replace("\r", "")
        with open(cache_file_path, "w") as f:
            f.write(freedict_db_index_data)
        return freedict_db_index_data

    def get_freedict_db_index():
        data = thread_last(
            get_freedict_db_index_data(),
            json.loads,
            (itlz.remove, get("software", default=None)),
            list,
        )
        for datum in data:
            assert "name" in dataum, "entries have language names"
        assert set(map(compose(len, flip(str.split, "-"), ig("name")), data)) == {
            2
        }, "language names are pairs"
        assert set(mapcat(compose(flip(str.split, "-"), ig("name")), data)) <= set(
            map(ig(0), lang_name_codes["rows"])
        ), "language name pair items are known language codes"
        return {"data": data}

    @wraps(fn)
    def wrapped(*args, **kwargs):
        return fn(get_freedict_db_index(), *args, **kwargs)

    return wrapped


ensure_freedict_db_index.cache_file_path = pth.join(
    gettempdir(), "freedict_db_index__pycache.tsv"
)
# ref. https://github.com/freedict/fd-dictionaries/wiki/FreeDict-API
ensure_freedict_db_index.download_url = "https://freedict.org/freedict-database.json"


@ensure_lang_name_codes
def lang_name_code_to_lang_name(lang_name_codes, lang_name_code):
    rows = lang_name_codes["rows"]
    code_to_name = {row[0]: row[1] for row in rows}
    if lang_name_code not in code_to_name:
        raise ValueError("unknown language name code", (lang_name_code,))
    return code_to_name[lang_name_code]


@ensure_lang_name_codes
def lang_name_to_lang_name_codes(lang_name_codes, lang_name):
    rows = lang_name_codes["rows"]

    def name_pred(name):
        return lang_name.lower() in name.lower()

    codes = thread_last(
        rows,
        (filter, compose_left(ig(1), name_pred)),
        (map, ig(0)),
        list,
    )
    # todo: return name->code {}
    return codes


@ensure_lang_name_codes
def get_bilingual_dictionary_downloads(lang_name_codes):
    cache_dir_path = get_bilingual_dictionary_downloads.cache_dir_path
    if pth.exists(cache_dir_path):
        assert pth.isdir(cache_dir_path)
    else:
        os.mkdir(cache_dir_path)
    urls = {
        "mid_omegawiki_index": "http://dictionarymid.sourceforge.net/dictionaries/dictsBinlingualsOmegaWiki.html",
        "mid_other_index": "http://dictionarymid.sourceforge.net/dictionaries/dictsOtherBilinguals.html",
        "digitaltibetan": "http://digitaltibetan.org/Media/Resources/",
    }

    def url_path_basename(url_path):
        return thread_last(url_path.split("/"), (filter, op.truth), list, itlz.last)

    def get_cache_filepath(url):
        parsed_url = requests.compat.urlparse(url)
        url_path_basename = url_path_basename(parsed_url.path)
        itlz.last(list(filter(op.truth, (parsed_url.path + "/").split("/"))))
        return pth.join(cache_dir_path, parsed_url.netloc + url_path_basename)

    assert len(urls) == len(
        map(get_cache_filepath, urls.values())
    ), "all index urls have unique cache location"

    def get_soup(url):
        cache_filepath = get_cache_filepath(url)
        if pth.exists(cache_filepath):
            with open(cache_filepath) as f:
                return BS(f.read())
        res = requests.get(url)
        assert res.status_code == 200
        with open(cache_filepath, "w") as f:
            return f.write(res.text)
        return BS(res.text)

    # BEGIN mid omegawiki
    soup = get_soup(urls["mid_omegawiki_index"])
    assert len(soup.find_all("table")) == 1
    soup.find_all("table")
    trows = soup.find_all("table")[0].find_all("tr")
    assert set(map(attrgetter("name"), trows[0].find_all(recursive=False))) == {
        "th"
    }, "first row consists of headers"
    headers = ["Language", "Download", "Web App", "Size"]
    assert (
        list(map(attrgetter("text"), trows[0].find_all(recursive=False))) == headers
    ), "found expected columns"
    body_trows = [r.find_all(recursive=False) for r in trows[1:]]
    for row in body_trows:
        assert set(map(attrgetter("name"), row.find_all(recursive=False))) == {
            "td"
        }, "table body rows consist of descriptors"
        assert (
            len(row[headers.index("Download")].find_all("a")) == 1
        ), "download rows contain precisely one anchor"
    download_urls = map(
        compose_left(
            get(headers.index("Download")),
            lambda el: el.find("a").get("href"),  # :/
            list,
        ),
        body_trows,
    )

    download_filenames = itlz.pipe(
        download_urls, requests.compat.urlparse, attrgetter("path"), url_path_basename
    )
    assert all(
        [filename.startswith("DfM_OmegaWiki_") for filename in download_filenames]
    )
    download_lang_dsl_names = thread_last(
        download_filenames,
        (map, compose_left(flip(str.split, "_"), get(2))),
    )
    for name in download_lang_dsl_names:
        assert len(name) == 6
        # .. split string on case change fn? ...  snake<>camel, etc.
        assert name[0].isupper() and name[3].isupper()
        assert (name[1:3] + name[4:]).islower()
    download_lang_names = [
        # match freedict name encoding
        name[:3] + "-" + name[3:]
        for name in download_lang_dsl_names
    ]

    assert set(mapcat(compose(flip(str.split, "-")), download_lang_names)) <= set(
        map(ig(0), lang_name_codes["rows"])
    ), (
        "language names from string typing "
        "of download filenames "
        "are known language codes"
    )
    omegawiki_dicts = list(zip(download_lang_names, download_filenames))
    # END mid omegawiki

    soup = get_soup(urls["mid_other_index"])

    breakpoint()
    raise NotImplementedError()


@ensure_lang_name_codes
def get_syllabary(lang_name_codes, lang_name_code):
    raise NotImplementedError()
    pass


# get_syllabary.cache_dir = pth.join()


get_bilingual_dictionary_downloads.cache_dir_path = pth.join(
    gettempdir(), "bilingal_dictionary_downloads_cache_dir"
)


get_lang_info = compose_left(
    lang_name_to_lang_name_codes,
    partial(map, juxt(ftlz.identity, lang_name_code_to_lang_name)),
    list,
)


def lookup_word_mono(word, lang="english"):
    """
    monolingual dictionary lookup
    """
    parser = WiktionaryParser()
    data = parser.fetch(word, lang)
    return data


def edit_text_terminal_curses(text):
    # startup
    stdscr = curses.initscr()
    curses.noecho()
    curses.cbreak()
    stdscr.keypad(True)
    ###

    height, width = stdscr.getmaxyx()
    editwin = curses.newwin(height - 10, width - 10, 1, 1)
    editwin.scrollok(True)
    curses.textpad.rectangle(stdscr, 0, 0, height - 9, width - 9)
    stdscr.refresh()

    box = curses.textpad.Textbox(editwin, insert_mode=True)
    for char in text:
        box.do_command(char)
    # Let the user edit until Ctrl-G is struck.
    box.edit()

    # Get resulting contents
    message = box.gather()

    # exit
    curses.nocbreak()
    stdscr.keypad(False)
    curses.echo()
    curses.endwin()

    return message



def rainbow_print(text):
    # Codes listed are from ECMA-48, Section 8.3.117, p. 61.
    # extracted from /usr/local/share/zsh/5.8/functions/Misc/colors
    ##
    # Attribute codes:
    _ATTRS = {
        name: '\033['+code+'m'
        for (code, name) in (
      ('00', 'none'),
      ('01', 'bold'),
      ('02', 'faint'),
        ('22', 'normal'),
      ('03', 'standout'),
               ('23', 'no-standout'),
      ('04', 'underline'),
          ('24', 'no-underline'),
      ('05', 'blink'),
        ('25', 'no-blink'),
      ('07', 'reverse'),
        ('27', 'no-reverse'),
      ('08', 'conceal'),
        ('28', 'no-conceal'),
                )}
    # Text color codes:
    _COLORS = {
        name: '\033['+code+'m'
        for (code, name) in (
      ('30', 'black'),
        ('40', 'bg-black'),
      ('31', 'red'),
        ('41', 'bg-red'),
      ('32', 'green'),
        ('42', 'bg-green'),
      ('33', 'yellow'),
        ('43', 'bg-yellow'),
      ('34', 'blue'),
        ('44', 'bg-blue'),
      ('35', 'magenta'),
        ('45', 'bg-magenta'),
      ('36', 'cyan'),
        ('46', 'bg-cyan'),
      ('37', 'white'),
        ('47', 'bg-white'),
    )}
    _COLOR_DEFAULTS = {
        name: '\033['+code+'m'
        for (code, name) in (
      ('39', 'default'),
        ('49', 'bg-default'),
                )}
    color_names = [color_name for color_name in
                   _COLORS.keys()
                   if not color_name.startswith('bg-')]
    for color_name, char in zip(color_names*math.ceil(len(text)/len(color_names)), text):
        print(_COLORS[color_name]+char, end='')
    print(_ATTRS['none'])



# todo:
#    * kill line
#    * maintain AST in parallel with text
#        - arrays of lines, lines of arrays
#    * i18n input methods, mathsym input method
#    * undo
#    * see Edit.highlight re. copy and paste impl
#    * additional cursor motion commands
#      - search text
#      - goto line
#    * use urwid Command Map
#    * allow editing in webbrowser
#      (see calc.py example)
def edit_text_terminal_urwid(edit_text, second_edit_text=None,
    word_re=r'[A-z]'
):
    class EditBox(urwid.Filler):
        region_bdry_marker = '|'

        def __init__(self, *args, **kwargs):
            edit_text = kwargs.pop('edit_text', '')
            self.edit = urwid.Edit(
                edit_text=edit_text,
                multiline=True,
            )
            super(EditBox, self).__init__(self.edit, *args, **kwargs)
            self.region_bdry = None

        def keypress(self, size, key):
            clipboard = edit_text_terminal_urwid.clipboard
            if key in ["ctrl n",]:
                key = 'down'
            elif key in ["ctrl p",]:
                key = 'up'
            elif key in ["ctrl b",]:
                key = 'left'
            elif key in ["ctrl f",]:
                key = 'right'
            elif key in ["ctrl a",]:
                key = 'home'
                if False:
                    edit_text_before = self.edit.get_edit_text()[:self.edit.edit_pos]
                    try:
                        newline_before = edit_text_before.rindex('\n')
                    except ValueError:
                        newline_before = -1
                    self.edit.set_edit_pos(newline_before+1)
                    return
            elif key in ["ctrl e",]:
                key = 'end'
                if False:
                    edit_text_after = self.edit.get_edit_text()[self.edit.edit_pos:]
                    try:
                        newline_after = edit_text_after.index('\n')
                    except ValueError:
                        newline_after = len(edit_text_after)
                    self.edit.set_edit_pos(self.edit.edit_pos+newline_after)
                    return
            ###
            elif key in ["meta <",]:
                self.edit.set_edit_pos(0)
            elif key in ["meta >",]:
                self.edit.set_edit_pos(len(self.edit.get_edit_text()))
            elif key in ["ctrl k",]:
                pass
            elif key in ["ctrl d",]:
                key = "delete"
            elif key in ["ctrl _",]:
                pass
            ###
            elif key in [
                    # "ctrl space"
                       "<0>",]:
                if self.region_bdry is None:
                    self.region_bdry = self.edit.edit_pos
                    self.edit.insert_text(
                        self.region_bdry_marker)
                    return
            elif key in ["meta w",]:
                if self.region_bdry is None:
                    return
                if self.edit.edit_pos <= self.region_bdry:
                    cp_text = self.edit.get_edit_text()[
                        self.edit.edit_pos:self.region_bdry]
                else:
                    cp_text = self.edit.get_edit_text()[
                        self.region_bdry+1:self.edit.edit_pos]
                clipboard.append(cp_text)
                self.edit.set_edit_text(
                    self.edit.get_edit_text()[:self.region_bdry]
                    +
                    self.edit.get_edit_text()[self.region_bdry+1:])
                self.region_bdry = None
                return
            elif key in ["ctrl w",]:
                if self.region_bdry is None:
                    return
                if self.edit.edit_pos <= self.region_bdry:
                    cut_text = self.edit.get_edit_text()[
                        self.edit.edit_pos:self.region_bdry]
                    self.edit.set_edit_text(
                        self.edit.get_edit_text()[:self.edit.edit_pos]
                        +
                        self.edit.get_edit_text()[self.region_bdry+1:])
                else:
                    cut_text = self.edit.get_edit_text()[
                        self.region_bdry+1:self.edit.edit_pos]
                    self.edit.set_edit_text(
                        self.edit.get_edit_text()[:self.region_bdry]
                        +
                        self.edit.get_edit_text()[self.edit.edit_pos:])
                    self.edit.set_edit_pos(self.region_bdry)
                clipboard.append(cut_text)
                self.region_bdry = None
                return
            elif key in ["ctrl y",]:
                if clipboard:
                    self.edit.insert_text(itlz.last(
                        clipboard))
                return
            elif key in ["ctrl u",]:
                try:
                    clipboard.pop()
                except IndexError:
                    pass
                return
            return super(EditBox, self).keypress(size, key)


    edit_box = EditBox(
        "top",
        edit_text=edit_text,
    )
    if second_edit_text is not None:
        second_edit_box = EditBox(
            "top",
            edit_text=second_edit_text,
        )
        main_loop_box = urwid.Columns([
            urwid.LineBox(
                edit_box,
            ),
            urwid.LineBox(
                second_edit_box,
            ),
        ])
    else:
        second_edit_box = None
        main_loop_box = urwid.LineBox(
            edit_box,
        )
    ###
    def unhandled_keypress(k):
        #
        if k in ["f10",]:
            raise urwid.ExitMainLoop()
        elif k in ["f9",]:
            edit_text_terminal_urwid.exit_flags.append("save")
            raise urwid.ExitMainLoop()
        ###
    #
    loop = urwid.MainLoop(
        main_loop_box,
        unhandled_input=unhandled_keypress,
    )
    loop.run()
    exit_flags = edit_text_terminal_urwid.exit_flags
    edit_text_terminal_urwid.clipboard = []
    edit_text_terminal_urwid.exit_flags = []
    return {
        'text': edit_box.edit.get_edit_text(),
        'second_text': (None if second_edit_box is None
                        else second_edit_box.edit.get_edit_text()),
        'exit_flags': exit_flags,
        'save': 'save' in exit_flags,
    }
edit_text_terminal_urwid.clipboard = []
edit_text_terminal_urwid.exit_flags = []


def edit_file_terminal(filename):
    filename = os.path.realpath(filename)
    with open(filename) as f:
        text_before = f.read()
    res = edit_text_terminal_urwid(text_before)
    text_after = res['text']
    with open(filename, 'w') as f:
        f.write(text_after)


# todo:
# * sieve/filter (name, time, etc.)
# * select-multiple/highlight items ['<0>']
# * optionally return filtered or selected list
# * scrollbar & mouse click to select
# retain cat-v-style minimalism, and
# implement separate mc clone otherwise.
def simple_file_browser_urwid(dirname='.'):
    if not pth.isdir(dirname):
        raise ValueError("not a directory",
                         (dirname,))
    ###
    list_walker = urwid.SimpleFocusListWalker([])
    def list_walker_modified_callback(
            list_walker, focus):
        for idx, ent in enumerate(list_walker):
            if isinstance(ent, urwid.AttrWrap):
                list_walker[idx] = ent.get_w()
        sel = list_walker[focus]
        hl_sel = urwid.AttrWrap(sel, 'focus')
        list_walker[focus] = hl_sel
    #
    def set_curr_dir(list_walker, name):
        simple_file_browser_urwid.curr_dir = (
            pth.abspath(name))
        filelist = (
            ['./', '../',] +
            [filename + (
                '/' if pth.isdir(
                    pth.join(name, filename))
                else '') for filename
             in os.listdir(name)]
        )
        list_walker.clear()
        list_walker += [
            urwid.Text(text) for text in filelist]
        list_walker_modified_callback(list_walker, 0)
    #
    set_curr_dir(list_walker, dirname)
    list_walker.set_focus_changed_callback(
        partial(list_walker_modified_callback,
                list_walker))
    def unhandled_keypress(key):
        if key in ["f10", "ctrl q"]:
            raise urwid.ExitMainLoop()
        elif key in ["enter"]:
            name, _ = (list_walker[list_walker.focus]
                       .get_w()
                       .get_text())
            if name[-1] == '/':
                set_curr_dir(
                    list_walker,
                    pth.join(
                        simple_file_browser_urwid.curr_dir,
                        name,
                    )
                )
        elif key in ["ctrl n"]:
            if list_walker.focus < len(list_walker) - 1:
                list_walker.focus += 1
        elif key in ["ctrl p"]:
            if list_walker.focus > 0:
                list_walker.focus -= 1
    ###
    listbox = urwid.ListBox(list_walker)
    view = urwid.Frame(listbox)
    palette = (
        ('focus', 'light gray', 'dark blue', 'standout'),
    )
    loop = urwid.MainLoop(
        view,
        palette,
        unhandled_input=unhandled_keypress,
    )
    loop.run()
    return pth.join(
        simple_file_browser_urwid.curr_dir,
        (list_walker[list_walker.focus]
         .get_w()
         .get_text())[0],
    )
simple_file_browser_urwid.curr_dir = None


def python_viewer_urwid(src):
    """ stepping-stone towoard src editor:
    use AST in parallel with text.
    - syntax highlighting
    - folding
    - goto definition
    - find occurences
    - opt line no.s
    """
    pass


def read_ics(filename):
    try:
        with zipfile.ZipFile(filename) as zf:
            ics_name = thread_last(
                zf.namelist(),
                (filter, compose_left(pth.splitext, ig(-1), partial(op.eq, ".ics"))),
                excepts((StopIteration,), first, handler=lambda _: None),
            )
            with zf.open(ics_name) as f:
                cal = ics.Calendar(f.read().decode("utf-8"))
    except zipfile.BadZipFile:
        with open(filename) as f:
            cal = ics.Calendar(f.read())
    return cal


# todo: timezone-aware
def ics_cal_busy_times_this_week(cal, disp=False):
    today = dt.date.today()
    mon = today - timedelta(days=today.weekday())
    if today.weekday() in [5, 6]:
        mon += timedelta(days=7)
    # mon = t.combine(mon, dt.time())
    fri = mon + timedelta(days=4)
    events_this_week = [
        ev for ev in cal.events if mon <= ev.begin.datetime.date() <= fri
    ]
    busy_times_this_week = [
        (ev.begin.datetime, ev.end.datetime) for ev in events_this_week
    ]
    busy_times_this_week.sort(key=ig(0))
    busy_times_by_day = groupby(
        compose(lambda d: d.date().weekday(), ig(0)), busy_times_this_week
    )
    day_abbrevs = ["M", "Tu", "W", "Th", "F"]
    day_abbrev_to_busy_times = dict(
        zip(
            day_abbrevs,
            get(list(range(len(day_abbrevs))), busy_times_by_day, default=[]),
        )
    )
    if not disp:
        return day_abbrev_to_busy_times
    for (day_abbrev, busy_times) in day_abbrev_to_busy_times.items():
        print(
            (
                day_abbrev
                + " "
                + ", ".join(
                    [
                        (
                            busy_time[0].strftime("%H:%M")
                            + "-"
                            + busy_time[1].strftime("%H:%M")
                        )
                        for busy_time in busy_times
                    ]
                )
            )
        )


def pastebin_app(port=5005, run_aio_srv=True):
    app = flask.Flask("pastebin")

    pastes = {}

    def heartbeat():
        while True:
            for pasteid in pastes:
                if paste_time < now:
                    pass

#    thread = threading.Thread(

    def store(text, f):
        pastes[str(uuid0.generate())] = {
            "text": text,
            "file": f,
        }

    def retrieve(pid):
        return pastes[pid]

    def paste_ids():
        return list(pastes.keys())

    @app.route("/download/<pid>/<filename>")
    def download(pid, filename):
        paste = retrieve(pid)
        if filename != paste["file"]["name"]:
            warn("url filename not equal to stored filename")
        return flask.send_file(
            BytesIO(paste["file"]["bytes"]),
            attachment_filename=paste["file"]["name"],
        )

    @app.route("/<pid>")
    def look(pid):
        if pid == "favicon.ico":
            return "", 404
        paste = retrieve(pid)
        return (
            (
                """
        <h3>{time}</h3>
        <p><pre>{text}</pre></p>
        """
            ).format(
                time=uuid0.UUID(pid).datetime.isoformat(),
                text=paste["text"],
            )
            + (
                (
                    """
        <a href="{get}">download</a>
        """
                ).format(
                    get=flask.url_for(
                        "download",
                        pid=pid,
                        filename=paste["file"]["name"],
                    ),
                )
                if paste["file"]
                else ""
            )
        )

    @app.route("/", methods=["GET", "POST"])
    def paste():
        text_name = "pastetext"
        file_name = "pastefile"
        if flask.request.method == "POST":
            text = flask.request.form[text_name]
            file_storage = flask.request.files[file_name]
            file_storage.mimetype
            file_name = file_storage.filename
            file_bytes = file_storage.read() if file_storage.filename else None
            store(
                text,
                {
                    "bytes": file_bytes,
                    "name": file_name,
                },
            )

        return """
        <form method="post" enctype="multipart/form-data">
            <textarea name={text} style="width:95vw; height:80vh;"></textarea>
            <p style="height:15vh;">
            <input type=file name={file_name}>
            <input type=submit value=PASTE>
            </p>
        </form>
        <h2>{list_prefix}pastes</h2>
        <ul>{paste_list}</ul>
    """.format(
            text=text_name,
            file_name=file_name,
            list_prefix=("" if paste_ids() else "no "),
            paste_list="".join(
                [
                    """<li><a href="{url}">{pid} - {time}</a></li>""".format(
                        url=flask.url_for("look", pid=pid),
                        time=uuid0.UUID(pid).datetime.isoformat(),
                        pid=pid,
                    )
                    for pid in paste_ids()
                ]
            ),
        )

    if not run_aio_srv:
        werkzeug.serving.run_simple(
            "0.0.0.0",
            port,
            app,
            use_debugger=True,
        )
        return

    # todo: error on Interrupt and rerun (build event loop).
    # todo: libuv
    flask_app = app
    loop = asyncio.get_event_loop()
    app = aioweb.Application(loop=loop)
    app.router.add_route(
        "*", "/{path_info:.*}",
       aiohttp_wsgi.WSGIHandler(flask_app.wsgi_app))
    aio_app = app
    aioweb.run_app(aio_app,
                   # host='localhost',
                   host="0.0.0.0",
                   port=port,
    )


def mouse_only_ui(cmd_arg):
    cmd = (shlex.split(cmd_arg)
            if isinstance(cmd_arg, (str,))
            else cmd_arg)
    if not isinstance(cmd, (list,)):
        raise ValueError()
    #
    app_state = {}
    def stdio_reader(file_obj_name):
        if file_obj_name not in ['stdout', 'stderr']:
            raise ValueError()
        proc = app_state['proc']
        file_obj = getattr(proc, file_obj_name)
        for line in iter((file_obj.readline
                          if file_obj else lambda: b""), b""):
            app_state[file_obj_name].append(
                line.decode("utf-8"))

    def on_go():
        if 'proc' in app_state and app_state['proc'].poll() is None:
            return
        proc = Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)
        app_state['proc'] = proc
        # workaround "pipe buffer deadlock"
        # also consider
        # * .communicate() with a future (?)
        # * passing a file object to stdout and stderr
        app_state['stdout'] = []
        app_state['stderr'] = []
        app_state['reader_threads'] = [
            threading.Thread(
                target=stdio_reader,
                args=('stdout',),
            ),
            threading.Thread(
                target=stdio_reader,
                args=('stderr',),
            ),
        ]
        for t in app_state['reader_threads']:
            t.start()

    def on_stop():
        if 'proc' not in app_state:
            return
        proc = app_state['proc']
        #
        for sig in [None, signal.SIGINT,
                signal.SIGKILL,
                signal.SIGTERM,]:
            if sig is not None:
                proc.send_signal(sig)
            if sig is None:
                if proc.poll() is None:
                    continue
                else:
                    break
            try:
                if sig is not None:
                    proc.wait(timeout=3)
            except subprocess.TimeoutExpired as ex:
                continue
            break
        else:
            raise RuntimeError("process didn't exit")
        #
        for t in app_state['reader_threads']:
            t.join()
        if proc.poll() != 0:
            print("error exit")
            print("stdout")
            print(('\n'.join(app_state['stdout'])
                   if app_state['stdout']
                   else "<None>"))
            print("stderr")
            print(('\n'.join(app_state['stderr'])
                   if app_state['stderr']
                   else "<None>"))
        del app_state['proc']
        del app_state['reader_threads']
        del app_state['stdout']
        del app_state['stderr']
    ###
    # ui
    root = tkinter.Tk()
    left_frame = tkinter.Frame(
            root,
#            relief="raised",
#            color="#200",
            )
    left_frame["bg"] = "purple"
    right_frame = tkinter.Frame(
            root,
            )
    right_frame["bg"] = "pink"
    left_frame.pack(
            side="left",
            fill="both",
            anchor="center",
            expand=True,
            )
    right_frame.pack(
            side="right",
            fill="y",
            )
    ##
    # https://stackoverflow.com/questions/42579927/rounded-button-tkinter-python
    # suggests using canvas.
    # elsewhere suggested to use image/bitmap
    class RoundButton(tkinter.Button, tkinter.Canvas):
        def __init__(self, *args, **kwargs):
            super().__init__(*args, **kwargs)
            # self.create_line(0, 0, 10, 10)
            self.create_line(*self.bbox("all"))
        #
        def _configure(self, *args, **kwargs):
            rv = super()._configure(*args, **kwargs)
            breakpoint()
            return rv
    ##
    go_btn = tkinter.Button(
            left_frame,
            text="Go!",
            command=on_go,
            relief="raised",
            )
    go_btn["bg"] = "#082"
    stop_btn = tkinter.Button(
            right_frame,
            text="stop",
            command=on_stop,
            )
    stop_btn["bg"] = "#086"
    go_btn.pack(
            side="bottom",
            # expand=True,
            fill="both",
            )
    stop_btn.pack(
            side="top",
            )
    root.mainloop()



# todo: use `del` to unclutter locals()


#########################################

def thread_loop_demo():


    mock_op = MagicMock()
    mock_op.side_effect = lambda _: random.random() > 0.5


    def thread_entry(thread_queue):
        pass


    thread_queue = queue.Queue()
    loop_thread = threading.Thread(target=thread_entry, args=(thread_queue,), daemon=True)
    loop_thread.start()
    for idx in range(10):
        thread_queue.put({"idx": idx})

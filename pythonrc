"""-*-python-*-
suggested use:
place a dotted symlink to this
file in your home directory
  ln -s /.../pythonrc ~/.pythonrc
and set the environment variable
PYTHONSTARTUP
to the symlink
export PYTHONSTARTUP="${HOME}/.pythonrc"
see also:
https://docs.python.org/3/using/cmdline.html#envvar-PYTHONSTARTUP
"""

from typing import (
    Dict,
)
from collections import (
    namedtuple,
)
import datetime as dt
from datetime import (
    datetime as dto,
    timedelta,
)
from functools import (
    reduce,
    partial,
    wraps,
)
from inspect import (
    getmembers as gm,
    getsource,
    getsourcefile as gsf,
    getmodule,
    ismodule,
    isclass,
)
import operator as op
from operator import (
    add,
    itemgetter as ig,
    attrgetter,
)
import os
import sys
import os.path as pth
from pprint import (
    pp,
    pprint,
)

import pydoc
from pydoc import (
    pager,
)

import curses
import curses.textpad


import subprocess
from subprocess import (
    Popen,
    PIPE,
)

import configparser

import pathlib

from io import (
    BytesIO,
    StringIO,
)

from warnings import warn

import zipfile

from tempfile import (
    gettempdir,
    mkdtemp,
)

import json

###


def ppp(obj):
    sio = StringIO()
    pprint(obj, stream=sio)
    pager(sio.getvalue())


def gmn(*args, **kwargs):
    return [m[0] for m in gm(*args, **kwargs)]


def gs(*args, **kwargs):
    pydoc.pager(getsource(*args, **kwargs))


class NameSpace:
    def __init__(self, obj):
        self._obj = obj

    def names(self):
        if ismodule(self._obj):
            return dir(self._obj)
        elif isclass(self._obj):
            return dir(self._obj)
        assert False, repr(self._obj) + " is not a module or class"

    def attrs(self):
        return map(partial(getattr, self._obj), self.names())

    def namespaces(self):
        [Namespace(attr) for attr in self.attrs() if any(juxt(ismodule, isclass)(attr))]


def pysearch_name(name, maxdepth=3):
    res = []
    permissive_getattr = excepts(
        (ModuleNotFoundError, AttributeError), partial(getattr), lambda _: None
    )

    def name_match(mname):
        return name in mname

    res += [sys.modules[mname] for mname in sys.modules.keys() if name_match(mname)]

    def search_class(cls):
        for mname in dir(cls):
            if name_match(mname):
                res.append(permissive_getattr(cls, mname))

    def search_module(module, depth):
        if depth > maxdepth:
            return
        if name in dir(module):
            res.append(permissive_getattr(module, name))
        for (mname, member) in [
            (mname, permissive_getattr(module, mname)) for mname in dir(module)
        ]:
            if not member:
                continue
            if name_match(mname):
                res.append(member)
            if isinstance(member, type):
                search_class(member)
            if ismodule(member):
                search_module(member, depth + 1)

    for mname in list(sys.modules.keys()):
        search_module(sys.modules[mname], 0)
    return res


ls = os.listdir


def cat(filepath, retstr=False):
    with open(filepath) as f:
        fstr = f.read()
    if retstr:
        return fstr
    pydoc.pager(fstr)


run = partial(
    subprocess.run,
    stdout=subprocess.PIPE,
    stderr=subprocess.PIPE,
    # shell=True,
    # check=True,
)


def run_1(cmd, timeout=None, stream=sys.stdout, err_stream=sys.stderr):
    def output_reader(proc):
        for line in iter(proc.stdout.readline, b""):
            print(line.decode("utf-8"), file=stream, end="")

    def err_reader(proc):
        for line in iter(proc.stderr.readline, b""):
            print(line.decode("utf-8"), file=err_stream, end="")

    proc = Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)
    tout = threading.Thread(target=output_reader, args=(proc,))
    terr = threading.Thread(target=err_reader, args=(proc,))
    tout.start()
    terr.start()
    proc.wait(timeout=timeout)
    t.join()
    t.join()


config = configparser.ConfigParser()
config.read(
    [
        os.path.join(os.path.dirname(os.path.realpath(__file__)), "python.conf"),
    ]
)


class PipInstallException(Exception):
    pass


def pip_install(package_name):
    name_to_specifier = {
        name: config["package-specifiers"][name]
        for name in config["package-specifiers"]
    }
    if package_name not in name_to_specifier:
        if os.getenv("PY_DBG_IMPORTS"):
            breakpoint()
        raise PipInstallException("unknown package", (package_name,))
    cmd = ["pip", "install", name_to_specifier[package_name]]
    res = subprocess.run(cmd)
    if res.returncode == 0:
        return
    raise PipInstallException("install failed", (res,))


###
_VENV_DIR = pth.join(str(pathlib.Path().home()), ".pyvenv")
_DEFAULT_VENV = pth.join(_VENV_DIR, "default")
if sys.prefix == sys.base_prefix:
    if not os.getenv("PY_CREATE_VENV"):
        raise Exception("not in venv.  set PY_CREATE_VENV to create")
    venv.create(_DEFAULT_VENV)
    print(". " + pth.join(_DEFAULT_VENV, "bin", "activate"))
    exit()


class ImportBlocker(object):
    def __init__(self):
        self.module_names = set()
        self.package_names = set()

    def find_module(self, fullname, path=None):
        if fullname.split(".")[0] in self.package_names:
            return self
        if fullname in self.module_names:
            return self
        return None

    def exec_module(self, mdl):
        # return an empty namespace
        return {}

    def create_module(self, spec):
        return None


import_blocker = ImportBlocker()
sys.meta_path.append(import_blocker)


def my_except_hook(exctype, value, traceback):
    if exctype is KeyboardInterrupt:
        print("see you later!")
    sys.__excepthook__(exctype, value, traceback)


def install_package(name):
    pass


sys.excepthook = my_except_hook

while True:
    try:
        import toolz
        import toolz.functoolz as ftlz
        import toolz.itertoolz as itlz
        import toolz.dicttoolz as dtlz
        from toolz.functoolz import (
            compose_left,
            excepts,
            compose,
            curry,
            flip,
            juxt,
            thread_last,
        )
        from toolz.itertoolz import (
            accumulate,
            concat,
            concatv,
            diff,
            first,
            isdistinct,
            groupby,
            mapcat,
            nth,
            unique,
        )
        from toolz.dicttoolz import (
            keymap,
            valmap,
            itemmap,
        )
        from toolz.curried import (
            get,
            keyfilter,
            valfilter,
            itemfilter,
        )

        import numpy as np
        import flask
        import werkzeug
        import ics
        import uuid0
        import lxml
        import pandas as pd
        import openpyxl
        import openpyxl.utils.dataframe
        import wiktionaryparser
        from wiktionaryparser import WiktionaryParser
        import shapely
        import matplotlib
        import requests
        import bs4
        from bs4 import BeautifulSoup as BS

        #        from matplotlib import pyplot

        sys.path.append(os.path.dirname(os.path.realpath(__file__)))
        import pyutils

        sys.path.pop()

    except ModuleNotFoundError as err:
        package_name = err.name
        try:
            print("attempting to install " + package_name)
            pip_install(package_name)
        except PipInstallException as ex:
            if os.getenv("PY_DBG_IMPORTS"):
                breakpoint()
            import_blocker.package_names.add(package_name)
        continue
    break


# reset to orig
# sys.excepthook = sys.__excepthook__

uninstalled_packages = import_blocker.package_names.copy()
if uninstalled_packages:
    print("uninstalled packages")
    print(uninstalled_packages)

###


def osm_to_shp(filename):
    with open(filename) as f:
        fstr = f.read()
        root = lxml.etree.XML(bytes(fstr, "utf-8"))
    tags = [t.tag for t in root]
    assert root.tag == "osm"
    assert set(tags) <= {"node", "relation", "way", "bounds"}
    assert root[0].tag == "bounds"
    assert set(tags[1:]) <= {"node", "relation", "way"}
    assert "way" not in tags or (set(tags[tags.index("way") :]) <= {"relation", "way"})
    assert "relation" not in tags or (
        set(tags[tags.index("relation") :]) <= {"relation"}
    )
    nodes = [el for el in root if el.tag == "node"]
    ways = [el for el in root if el.tag == "way"]
    relations = [el for el in root if el.tag == "relation"]
    bounds_dict = dict(root[0].items())
    min_bound = (bounds_dict["minlat"], bounds_dict["minlon"])
    max_bound = (bounds_dict["maxlat"], bounds_dict["maxlon"])
    # (beginnings of) some cleverness
    juxt(map(compose(keyfilter, flip(str.startswith)), ["min", "max"]))(bounds_dict)

    ### munging #

    breakpoint()
    el_attrs = lambda x: dict(x.items())
    attr_eq = lambda name, val: (compose(partial(op.eq, val), attrgetter(name)))
    has_tag = lambda el, tag_name: any(
        [
            True
            for x in el
            if (x.tag == "tag" and "k" in el_attrs(x) and el_attrs(x)["k"] == tag_name)
        ]
    )

    #    filter(compose_left(el_attrs, get('k'), partial(op.eq, 'highway')),
    #    filter(compose_left(el_attrs, flip(op.contains, 'k')),
    #        filter(compose(partial(op.eq, 'tag'), attrgetter('tag')),
    #            list(ways[2]))))

    waterways = list(filter(flip(has_tag, "waterway"), ways))
    highways = list(filter(flip(has_tag, "highway"), ways))
    named_highways = list(filter(flip(has_tag, "name"), highways))

    assert len(set(map(compose(ig("id"), el_attrs), nodes))) == len(
        nodes
    ), "nodes have unique ids"
    nodes_by_id = {el_attrs(n)["id"]: n for n in nodes}

    named_highways_lat_lons = ftlz.pipe(
        named_highways,
        partial(map, list),
        partial(
            map,
            compose_left(
                partial(filter, attr_eq("tag", "nd")),
                list,
            ),
        ),
        partial(
            map,
            compose_left(
                partial(
                    map,
                    compose_left(
                        el_attrs,
                        ig("ref"),
                        flip(get, nodes_by_id),
                    ),
                ),
                list,
            ),
        ),
        partial(
            map,
            compose_left(
                partial(
                    map,
                    compose_left(
                        el_attrs,
                        get(["lat", "lon"]),
                        compose(
                            list,
                            partial(map, float),
                        ),
                    ),
                ),
                list,
            ),
        ),
        list,
    )

    breakpoint()

    ways_keys = thread_last(
        ways,
        (mapcat, list),
        (filter, attr_eq("tag", "tag")),
        (map, el_attrs),
        (map, ig("k")),
        set,
    )

    breakpoint()

    relation = relations[0]


currfn = lambda: osm_to_shp("Downloads/map.osm")


def xlst_to_dataframes(filepath):
    wb = openpyxl.load_workbook(filepath)
    return {sn: pd.DataFrame(wb[sn].values) for sn in wb.sheetnames}


def dataframes_to_xlst(dfs: Dict[str, pd.DataFrame], filepath):
    wb = openpyxl.Workbook()
    wb.active
    for (nm, df) in dfs.items():
        ws = wb.create_sheet(nm)
        ws.title
        for row in openpyxl.utils.dataframe.dataframe_to_rows(
            df, index=True, header=True
        ):
            ws.append(row)
    wb.save(filepath)


def ensure_lang_name_codes(fn):
    cache_file_path = ensure_lang_name_codes.cache_file_path
    download_url = ensure_lang_name_codes.download_url

    def get_lang_name_codes_data():
        if pth.exists(cache_file_path):
            with open(cache_file_path) as f:
                return f.read()
        res = requests.get(download_url)
        assert res.status_code == 200
        lang_name_codes_data = res.text.replace("\r", "")
        with open(cache_file_path, "w") as f:
            f.write(lang_name_codes_data)
        return lang_name_codes_data

    def get_lang_name_codes():
        data = get_lang_name_codes_data()
        data = list(map(flip(str.split, "\t"), filter(op.truth, data.split("\n"))))
        assert data[0] == ["Id", "Print_Name", "Inverted_Name"]
        rows = data[1:]
        assert len(set(map(ig(0), rows))) == len(rows), "name codes are uniq"
        return {"rows": rows}

    @wraps(fn)
    def wrapped(*args, **kwargs):
        return fn(get_lang_name_codes(), *args, **kwargs)

    return wrapped


# todo: study pre-commit caching strategy
ensure_lang_name_codes.cache_file_path = pth.join(
    gettempdir(), "lang_name_codes__pycache.tsv"
)
# ref. https://iso639-3.sil.org/code_tables/download_tables
ensure_lang_name_codes.download_url = (
    "https://iso639-3.sil.org/sites/iso639-3/files/downloads/iso-639-3_Name_Index.tab"
)


@ensure_lang_name_codes
def ensure_freedict_db_index(lang_name_codes, fn):
    cache_file_path = ensure_freedict_db_index.cache_file_path
    download_url = ensure_freedict_db_index.download_url

    def get_freedict_db_index_data():
        if pth.exists(cache_file_path):
            with open(cache_file_path) as f:
                return f.read()
        res = requests.get(download_url)
        assert res.status_code == 200
        freedict_db_index_data = res.text.replace("\r", "")
        with open(cache_file_path, "w") as f:
            f.write(freedict_db_index_data)
        return freedict_db_index_data

    def get_freedict_db_index():
        data = thread_last(
            get_freedict_db_index_data(),
            json.loads,
            (itlz.remove, get("software", default=None)),
            list,
        )
        for datum in data:
            assert "name" in dataum, "entries have language names"
        assert set(map(compose(len, flip(str.split, "-"), ig("name")), data)) == {
            2
        }, "language names are pairs"
        assert set(mapcat(compose(flip(str.split, "-"), ig("name")), data)) <= set(
            map(ig(0), lang_name_codes["rows"])
        ), "language name pair items are known language codes"
        return {"data": data}

    @wraps(fn)
    def wrapped(*args, **kwargs):
        return fn(get_freedict_db_index(), *args, **kwargs)

    return wrapped


ensure_freedict_db_index.cache_file_path = pth.join(
    gettempdir(), "freedict_db_index__pycache.tsv"
)
# ref. https://github.com/freedict/fd-dictionaries/wiki/FreeDict-API
ensure_freedict_db_index.download_url = "https://freedict.org/freedict-database.json"


@ensure_lang_name_codes
def lang_name_code_to_lang_name(lang_name_codes, lang_name_code):
    rows = lang_name_codes["rows"]
    code_to_name = {row[0]: row[1] for row in rows}
    if lang_name_code not in code_to_name:
        raise ValueError("unknown language name code", (lang_name_code,))
    return code_to_name[lang_name_code]


@ensure_lang_name_codes
def lang_name_to_lang_name_codes(lang_name_codes, lang_name):
    rows = lang_name_codes["rows"]

    def name_pred(name):
        return lang_name.lower() in name.lower()

    codes = thread_last(
        rows,
        (filter, compose_left(ig(1), name_pred)),
        (map, ig(0)),
        list,
    )
    return codes


@ensure_lang_name_codes
def get_bilingual_dictionary_downloads(lang_name_codes):
    cache_dir_path = get_bilingual_dictionary_downloads.cache_dir_path
    if pth.exists(cache_dir_path):
        assert pth.isdir(cache_dir_path)
    else:
        os.mkdir(cache_dir_path)
    urls = {
        "mid_omegawiki_index": "http://dictionarymid.sourceforge.net/dictionaries/dictsBinlingualsOmegaWiki.html",
        "mid_other_index": "http://dictionarymid.sourceforge.net/dictionaries/dictsOtherBilinguals.html",
        "digitaltibetan": "http://digitaltibetan.org/Media/Resources/",
    }

    def url_path_basename(url_path):
        return thread_last(url_path.split("/"), (filter, op.truth), list, itlz.last)

    def get_cache_filepath(url):
        parsed_url = requests.compat.urlparse(url)
        url_path_basename = url_path_basename(parsed_url.path)
        itlz.last(list(filter(op.truth, (parsed_url.path + "/").split("/"))))
        return pth.join(cache_dir_path, parsed_url.netloc + url_path_basename)

    assert len(urls) == len(
        map(get_cache_filepath, urls.values())
    ), "all index urls have unique cache location"

    def get_soup(url):
        cache_filepath = get_cache_filepath(url)
        if pth.exists(cache_filepath):
            with open(cache_filepath) as f:
                return BS(f.read())
        res = requests.get(url)
        assert res.status_code == 200
        with open(cache_filepath, "w") as f:
            return f.write(res.text)
        return BS(res.text)

    # BEGIN mid omegawiki
    soup = get_soup(urls["mid_omegawiki_index"])
    assert len(soup.find_all("table")) == 1
    soup.find_all("table")
    trows = soup.find_all("table")[0].find_all("tr")
    assert set(map(attrgetter("name"), trows[0].find_all(recursive=False))) == {
        "th"
    }, "first row consists of headers"
    headers = ["Language", "Download", "Web App", "Size"]
    assert (
        list(map(attrgetter("text"), trows[0].find_all(recursive=False))) == headers
    ), "found expected columns"
    body_trows = [r.find_all(recursive=False) for r in trows[1:]]
    for row in body_trows:
        assert set(map(attrgetter("name"), row.find_all(recursive=False))) == {
            "td"
        }, "table body rows consist of descriptors"
        assert (
            len(row[headers.index("Download")].find_all("a")) == 1
        ), "download rows contain precisely one anchor"
    download_urls = map(
        compose_left(
            get(headers.index("Download")),
            lambda el: el.find("a").get("href"),  # :/
            list,
        ),
        body_trows,
    )

    download_filenames = itlz.pipe(
        download_urls, requests.compat.urlparse, attrgetter("path"), url_path_basename
    )
    assert all(
        [filename.startswith("DfM_OmegaWiki_") for filename in download_filenames]
    )
    download_lang_dsl_names = thread_last(
        download_filenames,
        (map, compose_left(flip(str.split, "_"), get(2))),
    )
    for name in download_lang_dsl_names:
        assert len(name) == 6
        # .. split string on case change fn? ...  snake<>camel, etc.
        assert name[0].isupper() and name[3].isupper()
        assert (name[1:3] + name[4:]).islower()
    download_lang_names = [
        # match freedict name encoding
        name[:3] + "-" + name[3:]
        for name in download_lang_dsl_names
    ]

    assert set(mapcat(compose(flip(str.split, "-")), download_lang_names)) <= set(
        map(ig(0), lang_name_codes["rows"])
    ), (
        "language names from string typing "
        "of download filenames "
        "are known language codes"
    )
    omegawiki_dicts = list(zip(download_lang_names, download_filenames))
    # END mid omegawiki

    soup = get_soup(urls["mid_other_index"])

    breakpoint()
    raise NotImplementedError()


get_bilingual_dictionary_downloads.cache_dir_path = pth.join(
    gettempdir(), "bilingal_dictionary_downloads_cache_dir"
)


get_lang_info = compose_left(
    lang_name_to_lang_name_codes,
    partial(map, juxt(ftlz.identity, lang_name_code_to_lang_name)),
    list,
)


def lookup_word_mono(word, lang="english"):
    """
    monolingual dictionary lookup
    """
    parser = WiktionaryParser()
    data = parser.fetch(word, lang)
    return data


def edit_text_terminal(text):
    # startup
    stdscr = curses.initscr()
    curses.noecho()
    curses.cbreak()
    stdscr.keypad(True)
    ###

    height, width = stdscr.getmaxyx()
    editwin = curses.newwin(height - 10, width - 10, 1, 1)
    editwin.scrollok(True)
    curses.textpad.rectangle(stdscr, 0, 0, height - 9, width - 9)
    stdscr.refresh()

    box = curses.textpad.Textbox(editwin, insert_mode=True)
    for char in text:
        box.do_command(char)
    # Let the user edit until Ctrl-G is struck.
    box.edit()

    # Get resulting contents
    message = box.gather()

    # exit
    curses.nocbreak()
    stdscr.keypad(False)
    curses.echo()
    curses.endwin()

    return message


def read_ics(filename):
    try:
        with zipfile.ZipFile(filename) as zf:
            ics_name = thread_last(
                zf.namelist(),
                (filter, compose_left(pth.splitext, ig(-1), partial(op.eq, ".ics"))),
                excepts((StopIteration,), first, handler=lambda _: None),
            )
            with zf.open(ics_name) as f:
                cal = ics.Calendar(f.read().decode("utf-8"))
    except zipfile.BadZipFile:
        with open(filename) as f:
            cal = ics.Calendar(f.read())
    return cal


# todo: timezone-aware
def ics_cal_busy_times_this_week(cal, disp=False):
    today = dt.date.today()
    mon = today - timedelta(days=today.weekday())
    if today.weekday() in [5, 6]:
        mon += timedelta(days=7)
    # mon = t.combine(mon, dt.time())
    fri = mon + timedelta(days=4)
    events_this_week = [
        ev for ev in cal.events if mon <= ev.begin.datetime.date() <= fri
    ]
    busy_times_this_week = [
        (ev.begin.datetime, ev.end.datetime) for ev in events_this_week
    ]
    busy_times_this_week.sort(key=ig(0))
    busy_times_by_day = groupby(
        compose(lambda d: d.date().weekday(), ig(0)), busy_times_this_week
    )
    day_abbrevs = ["M", "Tu", "W", "Th", "F"]
    day_abbrev_to_busy_times = dict(
        zip(
            day_abbrevs,
            get(list(range(len(day_abbrevs))), busy_times_by_day, default=[]),
        )
    )
    if not disp:
        return day_abbrev_to_busy_times
    for (day_abbrev, busy_times) in day_abbrev_to_busy_times.items():
        print(
            (
                day_abbrev
                + " "
                + ", ".join(
                    [
                        (
                            busy_time[0].strftime("%H:%M")
                            + "-"
                            + busy_time[1].strftime("%H:%M")
                        )
                        for busy_time in busy_times
                    ]
                )
            )
        )


def pastebin_app(port=5005):
    app = flask.Flask("pastebin")

    pastes = {}

    def store(text, f):
        pastes[str(uuid0.generate())] = {
            "text": text,
            "file": f,
        }

    def retrieve(pid):
        return pastes[pid]

    def paste_ids():
        return list(pastes.keys())

    @app.route("/download/<pid>/<filename>")
    def download(pid, filename):
        paste = retrieve(pid)
        if filename != paste["file"]["name"]:
            warn("url filename not equal to stored filename")
        return flask.send_file(
            BytesIO(paste["file"]["bytes"]),
            attachment_filename=paste["file"]["name"],
        )

    @app.route("/<pid>")
    def look(pid):
        if pid == "favicon.ico":
            return "", 404
        paste = retrieve(pid)
        return (
            (
                """
        <h3>{time}</h3>
        <p>{text}</p>
        """
            ).format(
                time=uuid0.UUID(pid).datetime.isoformat(),
                text=paste["text"],
            )
            + (
                (
                    """
        <a href="{get}">download</a>
        """
                ).format(
                    get=flask.url_for(
                        "download",
                        pid=pid,
                        filename=paste["file"]["name"],
                    ),
                )
                if paste["file"]
                else ""
            )
        )

    @app.route("/", methods=["GET", "POST"])
    def paste():
        text_name = "pastetext"
        file_name = "pastefile"
        if flask.request.method == "POST":
            text = flask.request.form[text_name]
            file_storage = flask.request.files[file_name]
            file_storage.mimetype
            file_name = file_storage.filename
            file_bytes = file_storage.read() if file_storage.filename else None
            store(
                text,
                {
                    "bytes": file_bytes,
                    "name": file_name,
                },
            )

        return """
        <form method="post" enctype="multipart/form-data">
            <textarea name={text} style="width:95vw; height:80vh;"></textarea>
            <p style="height:15vh;">
            <input type=file name={file_name}>
            <input type=submit value=PASTE>
            </p>
        </form>
        <h2>{list_prefix}pastes</h2>
        <ul>{paste_list}</ul>
    """.format(
            text=text_name,
            file_name=file_name,
            list_prefix=("" if paste_ids() else "no "),
            paste_list="".join(
                [
                    """<li><a href="{url}">{pid} - {time}</a></li>""".format(
                        url=flask.url_for("look", pid=pid),
                        time=uuid0.UUID(pid).datetime.isoformat(),
                        pid=pid,
                    )
                    for pid in paste_ids()
                ]
            ),
        )

    werkzeug.serving.run_simple(
        "0.0.0.0",
        port,
        app,
        use_debugger=True,
    )
